{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:red;'> Forecast Part is not set up here </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='color:red;'> Input Details </p>\n",
    "\n",
    "- All end dates (Train, Test and Forecast)\n",
    "- Specify date format\n",
    "- Provide data file name (file should be in csv format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, itertools, logging\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from prophet import Prophet\n",
    "from tbats import TBATS\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logger = logging.getLogger('cmdstanpy')\n",
    "logger.addHandler(logging.NullHandler())\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainStartDate = datetime(2018,1,1)\n",
    "trainEndDate = datetime(2022,1,1)\n",
    "testStartDate = datetime(2022,2,1)\n",
    "testEndDate = datetime(2023,1,1)\n",
    "forecastStartDate = datetime(2023, 2, 1)\n",
    "forecastEndDate = datetime(2024, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary functions for data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection\n",
    "def detect_outlier(x):\n",
    "    Q1 = np.quantile(x, 0.25)\n",
    "    Q3 = np.quantile(x, 0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return (x < Q1 - (1.5*IQR)) | (x > Q3 + (1.5*IQR))\n",
    "# Capping outlier value\n",
    "def cap_outliers(x):\n",
    "    Q1 = np.quantile(x, 0.25)\n",
    "    Q3 = np.quantile(x, 0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - (1.5*IQR)\n",
    "    upper_limit = Q3 + (1.5*IQR)\n",
    "    x_cap = np.where(x > upper_limit, upper_limit, np.where(x < lower_limit, lower_limit, x))\n",
    "    return x_cap\n",
    "# Function to print Quarter\n",
    "def date_quarter(date):\n",
    "    month = int(date.strftime('%m'))\n",
    "    year = int(date.strftime('%y'))\n",
    "    if month+2 > 12:\n",
    "        temp = f\"{calendar.month_abbr[month]}'{year}-{calendar.month_abbr[month + 2 - 12]}'{year+1}\"\n",
    "    else:\n",
    "        temp = f\"{calendar.month_abbr[month]}'{year}-{calendar.month_abbr[month + 2]}'{year}\"\n",
    "    return temp\n",
    "# MAPE (Mean Absolute Percentage Error)\n",
    "def MAPE(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "# Accuracy\n",
    "def Accuracy(mape):\n",
    "    return 100.0 - mape\n",
    "# Root Mean Square Error\n",
    "def RMSE(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "\n",
    "# Making function for data processing\n",
    "# ----------------------------------------------------------------------------\n",
    "def data_part(df, part):\n",
    "    Date = pd.date_range(trainStartDate - timedelta(days=1), testEndDate, freq = 'M') + timedelta(days = 1)\n",
    "    P1 = df[df['Part'] == part].reset_index(drop=True)\n",
    "    P2 = P1.groupby(['Date'])['Quantity'].sum().reset_index()\n",
    "    P2.set_index('Date', inplace = True)\n",
    "    temp = pd.DataFrame(P2, index = Date)\n",
    "    temp['Flag NA'] = temp['Quantity'].apply(lambda x: np.isnan(x))\n",
    "    temp = temp[temp[temp['Flag NA'] == False].index[0]:]\n",
    "    temp.fillna(method = 'ffill', inplace = True)\n",
    "    temp['Outlier'] = detect_outlier(temp['Quantity'])\n",
    "    temp['Quantity'] = cap_outliers(temp['Quantity'].values)\n",
    "    temp_df = pd.DataFrame(data = [np.sum(temp['Quantity'][(3*i-3):(3*i)]) for i in range(1,1+int(len(temp)/3))],\n",
    "                           index = [temp.index[3*i-3] for i in range(1,1+int(len(temp)/3))], columns = ['Quantity'])\n",
    "    return temp_df\n",
    "# ADF test\n",
    "def adf_test(series):\n",
    "    result = adfuller(series)\n",
    "    if result[1] < 0.05:\n",
    "        d = 0\n",
    "    else:\n",
    "        d = 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================================================================\n",
    "#                                        Halt Winter\n",
    "# -----------------------------------------------------------------------------------------------------------\n",
    "def RUN_HW(df, part):\n",
    "    best_rmse = float(\"inf\")\n",
    "    best_comb = None\n",
    "    best_abg = None\n",
    "    best_mape = None\n",
    "    best_acc = None\n",
    "    best_pred = None\n",
    "\n",
    "    # Getting data for each group\n",
    "    demo_data = data_part(df, part)\n",
    "    # Data splitting\n",
    "    train_data = demo_data[:trainEndDate]\n",
    "    test_data = demo_data[trainEndDate + timedelta(days = 1):testEndDate]\n",
    "    forecast_dates = pd.date_range(testEndDate, forecastEndDate, freq = 'M') + timedelta(days = 1)\n",
    "    n = len(test_data)\n",
    "    m = len(forecast_dates)\n",
    "    y_true = test_data['Quantity']\n",
    "    # Making all possible combination\n",
    "    values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    all_combination = list(itertools.product(['add', 'mul'], ['add', 'mul']))\n",
    "    abg_combination = list(itertools.product(values, values, values))\n",
    "\n",
    "    for comb in tqdm(all_combination, desc = f'\\nPart {part}', leave = False):\n",
    "        for abg in tqdm(abg_combination, desc = 'Searching for best ABG ', leave = False):\n",
    "            alpha, beta, gamma = abg\n",
    "            try:\n",
    "                hw_model = ExponentialSmoothing(train_data[\"Quantity\"], trend=comb[0], seasonal=comb[1], seasonal_periods=12,damped = False)\n",
    "                model = hw_model.fit(smoothing_level=alpha, smoothing_slope=beta, smoothing_seasonal=gamma)\n",
    "                y_pred = model.predict(start=test_data.index[0], end=test_data.index[-1])\n",
    "                mape = MAPE(y_true, y_pred)\n",
    "                acc = Accuracy(mape)\n",
    "                rmse = RMSE(y_true, y_pred)\n",
    "                if rmse < best_rmse:\n",
    "                    best_rmse = rmse\n",
    "                    best_comb = comb\n",
    "                    best_abg = abg\n",
    "                    best_mape = mape\n",
    "                    best_acc = acc\n",
    "                    best_pred = y_pred\n",
    "            except:\n",
    "                pass\n",
    "    hw_final_model = ExponentialSmoothing(train_data[\"Quantity\"], trend=best_comb[0], seasonal=best_comb[1], seasonal_periods=12,damped = False)\n",
    "    final_model = hw_final_model.fit(smoothing_level = best_abg[0], smoothing_slope = best_abg[1], smoothing_seasonal = best_abg[2])\n",
    "    forecast = final_model.predict(start = testEndDate+timedelta(days=1), end = forecastEndDate)\n",
    "    temp = pd.DataFrame({'Part':np.repeat(part,n), \n",
    "                         'Date':test_data.index.values, \n",
    "                         'Original':test_data.Quantity.values, \n",
    "                         'Prediction':best_pred.values, \n",
    "                         'MAPE':np.repeat(best_mape,n), \n",
    "                         'RMSE':np.repeat(best_rmse,n), \n",
    "                         'Accuracy':np.repeat(best_acc,n)})\n",
    "    temp.insert(6, 'Order', [(best_comb, best_abg) for i in range(n)])\n",
    "    forecast_df = pd.DataFrame({'Part':np.repeat(part,m), \n",
    "                                'Date':forecast_dates.values, \n",
    "                                'Forecast':forecast.values})\n",
    "    forecast_df.insert(3, 'Order', [(best_comb, best_abg) for i in range(m)])\n",
    "    return temp, forecast_df\n",
    "\n",
    "# ===========================================================================================================\n",
    "#                          Auto Regressive Moving Average (ARMA)\n",
    "# -----------------------------------------------------------------------------------------------------------\n",
    "def RUN_ARMA(df, part):\n",
    "    best_rmse = float(\"inf\")\n",
    "    best_order = None\n",
    "    best_mape = None\n",
    "    best_acc = None\n",
    "    best_pred = None\n",
    "\n",
    "    # Getting data for each group\n",
    "    demo_data = data_part(df, part)\n",
    "\n",
    "    # Data splitting\n",
    "    train_data = demo_data[:trainEndDate]\n",
    "    test_data = demo_data[trainEndDate + timedelta(days = 1):testEndDate]\n",
    "    forecast_dates = pd.date_range(testEndDate, forecastEndDate, freq = 'M') + timedelta(days = 1)\n",
    "    n = len(test_data)\n",
    "    m = len(forecast_dates)\n",
    "    y_true = test_data['Quantity']\n",
    "    \n",
    "    p = range(0, 12)\n",
    "    d = [0]\n",
    "    q = range(0, 12)\n",
    "    pdq_combination = list(itertools.product(p,d,q))\n",
    "    \n",
    "    for order in tqdm(pdq_combination, desc = f'\\nPart: {part}', leave = False):\n",
    "        try:\n",
    "            model = ARIMA(train_data['Quantity'], order=order).fit()\n",
    "            y_pred = model.predict(start=test_data.index[0], end=test_data.index[-1])\n",
    "            mape = MAPE(y_true, y_pred)\n",
    "            acc = Accuracy(mape)\n",
    "            rmse = RMSE(y_true, y_pred)\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_order = order\n",
    "                best_mape = mape\n",
    "                best_acc = acc\n",
    "                best_pred = y_pred\n",
    "        except:\n",
    "            pass\n",
    "    final_model = ARIMA(train_data['Quantity'], order = best_order).fit()\n",
    "    forecast = final_model.predict(start = testEndDate + timedelta(days=1), end = forecastEndDate)\n",
    "    temp = pd.DataFrame({'Part':np.repeat(part,n),\n",
    "                         'Date':test_data.index.values, \n",
    "                         'Original':test_data.Quantity.values, \n",
    "                         'Prediction':best_pred.values, \n",
    "                         'MAPE':np.repeat(best_mape,n), \n",
    "                         'RMSE':np.repeat(best_rmse,n), \n",
    "                         'Accuracy':np.repeat(best_acc,n)})\n",
    "    temp.insert(6, 'Order', [best_order for i in range(n)])\n",
    "    \n",
    "    forecast_df = pd.DataFrame({'Part':np.repeat(part,m),\n",
    "                         'Date':forecast_dates.values, \n",
    "                         'Forecast':forecast.values})\n",
    "                                \n",
    "    forecast_df.insert(3, 'Order', [best_order for i in range(m)])\n",
    "    return temp, forecast_df\n",
    "\n",
    "\n",
    "# ===========================================================================================================\n",
    "#                                  Auto Regressive Integrated Moving Average (ARIMA)\n",
    "# -----------------------------------------------------------------------------------------------------------\n",
    "def RUN_ARIMA(df, part):\n",
    "    best_rmse = float(\"inf\")\n",
    "    best_order = None\n",
    "    best_mape = None\n",
    "    best_acc = None\n",
    "    best_pred = None\n",
    "    # Getting data for each group\n",
    "    demo_data = data_part(df, part)\n",
    "    \n",
    "    # Data splitting\n",
    "    train_data = demo_data[:trainEndDate]\n",
    "    test_data = demo_data[trainEndDate + timedelta(days = 1):testEndDate]\n",
    "    forecast_dates = pd.date_range(testEndDate, forecastEndDate, freq = 'M') + timedelta(days = 1)\n",
    "    n = len(test_data)\n",
    "    m = len(forecast_dates)\n",
    "    y_true = test_data['Quantity']\n",
    "    \n",
    "    # Defining possible combination set\n",
    "    p = range(0, 10)\n",
    "    d = [adf_test(demo_data['Quantity'])]\n",
    "    q = range(0, 10)\n",
    "    pdq_combination = list(itertools.product(p,d,q))\n",
    "    \n",
    "    for pdq in tqdm(pdq_combination, desc = f'\\nPart: {part}', leave = False):\n",
    "        try:\n",
    "            model = ARIMA(train_data['Quantity'], order=pdq).fit()\n",
    "            y_pred = model.predict(start=test_data.index[0], end=test_data.index[-1])\n",
    "            mape = MAPE(y_true, y_pred)\n",
    "            acc = Accuracy(mape)\n",
    "            rmse = RMSE(y_true, y_pred)\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_order = pdq\n",
    "                best_mape = mape\n",
    "                best_acc = acc\n",
    "                best_pred = y_pred\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # final model\n",
    "    ARIMA_final_model = ARIMA(train_data['Quantity'], order=best_order).fit()\n",
    "    forecast = ARIMA_final_model.predict(start = testEndDate + timedelta(days=1), end = forecastEndDate)\n",
    "    temp = pd.DataFrame({'Part':np.repeat(part,n), \n",
    "                         'Date':test_data.index.values, \n",
    "                         'Original':test_data.Quantity.values, \n",
    "                         'Prediction':best_pred.values, \n",
    "                         'MAPE':np.repeat(best_mape,n), \n",
    "                         'RMSE':np.repeat(best_rmse,n), \n",
    "                         'Accuracy':np.repeat(best_acc,n)})\n",
    "    temp.insert(6, 'Order', [best_order for i in range(n)])\n",
    "\n",
    "\n",
    "    forecast_df = pd.DataFrame({'Part':np.repeat(part,m), \n",
    "                         'Date':forecast_dates.values, \n",
    "                         'Forecast':forecast.values})\n",
    "    forecast_df.insert(3, 'Order', [best_order for i in range(m)])\n",
    "    return temp, forecast_df\n",
    "\n",
    "# ===========================================================================================================\n",
    "#                          Seasonal Auto Regressive Integrated Moving Average (SARIMA)\n",
    "# -----------------------------------------------------------------------------------------------------------\n",
    "def RUN_SARIMA(df, part):\n",
    "    best_rmse = float(\"inf\")\n",
    "    best_pdq = None\n",
    "    best_pdqs = None\n",
    "    best_mape = None\n",
    "    best_acc = None\n",
    "    best_pred = None\n",
    "\n",
    "    # Getting data for each group\n",
    "    demo_data = data_part(df, part)\n",
    "\n",
    "    # Data splitting\n",
    "    train_data = demo_data[:trainEndDate]\n",
    "    test_data = demo_data[trainEndDate + timedelta(days = 1):testEndDate]\n",
    "    forecast_dates = pd.date_range(testEndDate, forecastEndDate, freq = 'M') + timedelta(days = 1)\n",
    "    n = len(test_data)\n",
    "    m = len(forecast_dates)\n",
    "    y_true = test_data['Quantity']\n",
    "\n",
    "    #All possible combinations\n",
    "    p = range(0,3)\n",
    "    d = [adf_test(demo_data['Quantity'])]\n",
    "    q = range(0, 3)\n",
    "    P = range(0, 3)\n",
    "    D = [0,1]\n",
    "    Q = range(0, 3)\n",
    "    s = [3, 6, 12]\n",
    "    pdq_combination = list(itertools.product(p,d,q))\n",
    "    PDQs_combination = list(itertools.product(P, D, Q, s))\n",
    "    \n",
    "    for pdq in tqdm(pdq_combination, desc = f'\\nPart {part}', leave = False):\n",
    "        for PDQs in tqdm(PDQs_combination, desc = 'Searching for best combination', leave = False):\n",
    "            try:\n",
    "                model = SARIMAX(train_data['Quantity'], order = pdq, seasonal_order = PDQs).fit()\n",
    "                y_pred = model.predict(start = test_data.index[0], end = test_data.index[-1])\n",
    "                y_true = test_data['Quantity']\n",
    "                mape = MAPE(y_true, y_pred)\n",
    "                acc = Accuracy(mape)\n",
    "                rmse = RMSE(y_true, y_pred)\n",
    "                \n",
    "                if rmse < best_rmse:\n",
    "                    best_rmse = rmse\n",
    "                    best_mape = mape\n",
    "                    best_acc = acc\n",
    "                    best_pred = y_pred\n",
    "                    best_pdq = pdq\n",
    "                    best_pdqs = PDQs\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    temp = pd.DataFrame({'Part':np.repeat(part,n), \n",
    "                         'Date':test_data.index.values, \n",
    "                         'Original':test_data.Quantity.values, \n",
    "                         'Prediction':best_pred.values, \n",
    "                         'MAPE':np.repeat(best_mape,n), \n",
    "                         'RMSE':np.repeat(best_rmse,n), \n",
    "                         'Accuracy':np.repeat(best_acc,n)})\n",
    "    temp.insert(6, 'Order', [(best_pdq, best_pdqs) for i in range(n)])\n",
    "    \n",
    "    # Forecasting\n",
    "    final_model = SARIMAX(train_data['Quantity'], order = best_pdq, seasonal_order = best_pdqs).fit()\n",
    "    s = testEndDate + timedelta(days=1)\n",
    "    e = forecastEndDate\n",
    "    forecast = final_model.predict(start=s, end=e)\n",
    "    forecast_df = pd.DataFrame({'Part':np.repeat(part,m),\n",
    "                                \"Date\": forecast_dates.values ,\n",
    "                                \"Forecast\": forecast.values})\n",
    "    forecast_df.insert(3, 'Order', [(best_pdq, best_pdqs) for i in range(m)])\n",
    "    \n",
    "    return temp, forecast_df\n",
    "\n",
    "# ===========================================================================================================\n",
    "#                                                   TBATS\n",
    "# -----------------------------------------------------------------------------------------------------------\n",
    "def RUN_TBATS(df, part):\n",
    "    best_rmse = float(\"inf\")\n",
    "    best_sp = None\n",
    "    best_mape = None\n",
    "    best_acc = None\n",
    "    best_pred = None\n",
    "\n",
    "    # Getting data for each group\n",
    "    demo_data = data_part(df, part)\n",
    "    sp_values = [3, 4, 5, 6, 8, 9, 12]\n",
    "\n",
    "    # Data splitting\n",
    "    train_data = demo_data[:trainEndDate]\n",
    "    test_data = demo_data[trainEndDate + timedelta(days = 1):testEndDate]\n",
    "    forecast_dates = pd.date_range(forecastStartDate - timedelta(days = 1), forecastEndDate, freq='M') + timedelta(days = 1)\n",
    "    n = len(test_data)\n",
    "    m = len(forecast_dates)\n",
    "    y_true = test_data['Quantity']\n",
    "    \n",
    "    for sp in tqdm(sp_values, desc = 'Searching over possible seasonal periods', leave = False):\n",
    "        try:\n",
    "            model = TBATS(seasonal_periods=[sp]).fit(train_data.Quantity)\n",
    "            y_pred = model.forecast(steps=n)\n",
    "            mape = MAPE(y_true, y_pred)\n",
    "            acc = Accuracy(mape)\n",
    "            rmse = RMSE(y_true, y_pred)\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_sp = sp\n",
    "                best_mape = mape\n",
    "                best_acc = acc\n",
    "                best_pred = y_pred\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    final_model = TBATS(seasonal_periods=[best_sp]).fit(train_data.Quantity) \n",
    "    y_forecast = final_model.forecast(steps=12+m)\n",
    "    \n",
    "    temp_df = pd.DataFrame({'Part':np.repeat(part,n), \n",
    "                         'Date':test_data.index.values, \n",
    "                         'Original':test_data.Quantity.values, \n",
    "                         'Prediction':[best_pred[i] for i in range(0, n)], \n",
    "                         'MAPE':np.repeat(best_mape,n), \n",
    "                         'RMSE':np.repeat(best_rmse,n), \n",
    "                         'Accuracy':np.repeat(best_acc,n)})\n",
    "    temp_df.insert(6, 'Order', [(best_sp) for i in range(n)])\n",
    "    \n",
    "    forecast_df = pd.DataFrame({'Part':np.repeat(part, m), \n",
    "                         'Date':forecast_dates.values, \n",
    "                         'Forecast':[y_forecast[n-1+i] for i in range(0, m)]})\n",
    "    forecast_df.insert(3, 'Order', [(best_sp) for i in range(m)])\n",
    "    \n",
    "    return temp_df, forecast_df\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "#                                   Prophet\n",
    "# ----------------------------------------------------------------------------\n",
    "def RUN_PROPHET(df, part):\n",
    "    rmse = float(\"inf\")\n",
    "    mape = None\n",
    "    acc = None\n",
    "\n",
    "    # Getting data for each group\n",
    "    demo_data = data_part(df, part)\n",
    "    demo_data.reset_index(level=0, inplace=True)\n",
    "    demo_data.columns = ['Date', 'Quantity', 'Flag NA', 'Outlier']\n",
    "\n",
    "    # Data splitting\n",
    "    testEndDate = demo_data.index.values[-1]\n",
    "    train_data = demo_data.iloc[:demo_data.index[demo_data.Date == trainEndDate].values[0]]\n",
    "    test_data = demo_data.iloc[demo_data.index[demo_data.Date == trainEndDate].values[0]+1:testEndDate]\n",
    "    train_data = train_data[[\"Date\", \"Quantity\"]]\n",
    "    train_data.columns = ['ds', 'y']\n",
    "    test_period = pd.DataFrame(test_data[\"Date\"])\n",
    "    test_period.columns = ['ds']\n",
    "    y_true = test_data['Quantity']\n",
    "    n = len(test_data)\n",
    "    forecast_dates = pd.date_range(forecastStartDate - timedelta(days = 1), forecastEndDate , freq='M') + timedelta(days = 1)\n",
    "    \n",
    "    try:\n",
    "        model = Prophet()\n",
    "        model.fit(train_data)\n",
    "        prediction = model.predict(test_period)\n",
    "        y_pred = prediction[\"yhat\"]\n",
    "        mape = MAPE(y_true, y_pred)\n",
    "        acc = Accuracy(mape)\n",
    "        rmse = RMSE(y_true, y_pred)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    forecast_period = pd.DataFrame(forecast_dates)\n",
    "    forecast_period.columns = ['ds']\n",
    "    m = len(forecast_period)\n",
    "    forecast = model.predict(forecast_period)\n",
    "    y_forecast = forecast[\"yhat\"]\n",
    "    \n",
    "    temp_df = pd.DataFrame({'Part':np.repeat(part,n), \n",
    "                         'Date':test_data.Date.values, \n",
    "                         'Original':test_data.Quantity.values, \n",
    "                         'Prediction':[y_pred[i] for i in range(0, n)], \n",
    "                         'MAPE':np.repeat(mape,n), \n",
    "                         'RMSE':np.repeat(rmse,n), \n",
    "                         'Accuracy':np.repeat(acc,n)})\n",
    "    temp_df.insert(6, 'Order', [np.nan for i in range(n)])\n",
    "    \n",
    "    forecast_df = pd.DataFrame({'Part':np.repeat(part,m), \n",
    "                         'Date':forecast_period.ds.values, \n",
    "                         'Forecast':[y_forecast[i] for i in range(0, m)]})\n",
    "    forecast_df.insert(3, 'Order', [np.nan for i in range(m)])\n",
    "    \n",
    "    return temp_df, forecast_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RUN_MODEL(date_format, data_file_name, model, model_fun):\n",
    "    # Load the data and data processing ------------------------------------------\n",
    "    data = pd.read_csv(f'./../data/{data_file_name}.csv', low_memory = False, encoding= 'unicode_escape')\n",
    "    df = data[['Part','Customer Desc','Date','Quantity']]\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], format = date_format)\n",
    "    # Define SKU list ------------------------------------------------------------\n",
    "    sku_set = df['Part'].unique()[:2]\n",
    "    # Run all SKU for a specific model -------------------------------------------\n",
    "    print(f'MODEL: {model} || Running for {len(sku_set)} parts: ')\n",
    "    prediction_df = pd.DataFrame()\n",
    "    forecast_df = pd.DataFrame()\n",
    "    for part in tqdm(sku_set, desc = 'Over All Parts'):\n",
    "        output = model_fun(df, part)\n",
    "        prediction_df = pd.concat([prediction_df, output[0]], ignore_index = True)\n",
    "        forecast_df = pd.concat([forecast_df, output[1]], ignore_index = True)\n",
    "    prediction_df.insert(2, 'Quarter', prediction_df['Date'].apply(date_quarter))\n",
    "    forecast_df.insert(2, 'Quarter', forecast_df['Date'].apply(date_quarter))\n",
    "    summary_df = prediction_df[['Part','MAPE','RMSE','Accuracy','Order']]\n",
    "    summary_df.drop_duplicates(inplace = True)\n",
    "    summary_df.reset_index(drop = True, inplace = True)\n",
    "    summary_df['Model'] = np.repeat('Model', len(sku_set))\n",
    "\n",
    "    prediction_df.to_csv(f'./../resultQ/prediction_{model}_{len(sku_set)}.csv', index = False)\n",
    "    forecast_df.to_csv(f'./../resultQ/forecast_{model}_{len(sku_set)}.csv', index = False)\n",
    "    summary_df.to_csv(f'./../resultQ/summary_{model}_{len(sku_set)}.csv', index = False)\n",
    "\n",
    "    print(f\"Average MAPE for {model}: {summary_df['MAPE'].mean()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally Run All model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: ARIMA || Running for 2 parts: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ff3c554c894d21aee789c6e5f7a27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Over All Parts'), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='\\nPart: 300000904'), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-39c4f4dc77cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# RUN_MODEL(date_format, data_file_name, 'HW', RUN_HW)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# RUN_MODEL(date_format, data_file_name, 'ARMA', RUN_ARMA)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mRUN_MODEL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ARIMA'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRUN_ARIMA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# RUN_MODEL(date_format, data_file_name, 'SARIMA', RUN_SARIMA)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# RUN_MODEL(date_format, data_file_name, 'TBATS', RUN_TBATS)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-3f8e43b35896>\u001b[0m in \u001b[0;36mRUN_MODEL\u001b[1;34m(date_format, data_file_name, model, model_fun)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mforecast_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msku_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Over All Parts'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mprediction_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprediction_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mforecast_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mforecast_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-a9c396262d1d>\u001b[0m in \u001b[0;36mRUN_ARIMA\u001b[1;34m(df, part)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m     forecast_df = pd.DataFrame({'Part':np.repeat(part,m), \n\u001b[0m\u001b[0;32m    178\u001b[0m                          \u001b[1;34m'Date'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mforecast_dates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                          'Forecast':forecast.values})\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         ]\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "# Function input\n",
    "# -----------------------------------------------------------------------------\n",
    "date_format = '%d-%b-%y'\n",
    "data_file_name = ''\n",
    "\n",
    "RUN_MODEL(date_format, data_file_name, 'HW', RUN_HW)\n",
    "RUN_MODEL(date_format, data_file_name, 'ARMA', RUN_ARMA)\n",
    "RUN_MODEL(date_format, data_file_name, 'ARIMA', RUN_ARIMA)\n",
    "RUN_MODEL(date_format, data_file_name, 'SARIMA', RUN_SARIMA)\n",
    "RUN_MODEL(date_format, data_file_name, 'TBATS', RUN_TBATS)\n",
    "RUN_MODEL(date_format, data_file_name, 'PROBHET', RUN_PROPHET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
